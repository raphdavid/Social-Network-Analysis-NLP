{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading file\n",
    "filename = 'SNA_Res_100_pdfs_combinedTxt.txt'\n",
    "file = open(filename, encoding = \"utf8\")\n",
    "text = file.read()\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = text.split()\n",
    "words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove punctuation\n",
    "import re\n",
    "p = re.compile(r'[^\\w\\s]+')\n",
    "without_punct = [p.sub('', x) for x in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "without_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "#nltk.download('punkt')\n",
    "#nltk.download('words')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#adding more stopwords\n",
    "all_stopwords = stopwords.words('english')\n",
    "newStopWords = ['also','within','et','al','may','maybe','one','two','three',\n",
    "                'four','five','six','seven','eight','nine','groups','group',\n",
    "                'fig','table','use','used','journal','eg']\n",
    "all_stopwords.extend(newStopWords)\n",
    "\n",
    "all_stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#filtering out stopwords\n",
    "without_stopwords = [word for word in without_punct if word.casefold() not in all_stopwords]\n",
    "print(without_stopwords[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing numbers\n",
    "n = re.compile(r'\\d+') \n",
    "without_num = [n.sub('', x) for x in without_stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing single letters ex. \"B\" or \"G\"\n",
    "without_initials = [x for x in without_stopwords if len(x) !=1]      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = without_initials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop blanks\n",
    "df = df[df[0] != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show top words\n",
    "word_freq = df[0].value_counts().to_dict()\n",
    "word_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get body of each text\n",
    "file_list = glob.glob(os.path.join(os.getcwd(), \"SNA_RES_100_pdfs_R_txt\", \"*.txt\"))\n",
    "\n",
    "texts = []\n",
    "#append the body of each text to the list texts\n",
    "for text in file_list:\n",
    "    with open(text) as f_input:\n",
    "        texts.append(f_input.read())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#unsure as to whether or not I have all of the texts, the data does not end with \"...\" and seems too short\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if the most frequent words appears\n",
    "#for each article there is a dictionary of words that appear in most frequent words, dictionaroes will be different sizes\n",
    "#get a matrix from these dictionaries  (100 x 2000)\n",
    "\n",
    "\n",
    "#use dictionary -> search 2000 times for each article\n",
    "#1) build a dictionary for each article\n",
    "#for loop to check each of the most frequent word to see if it occurs in the article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the names of the files\n",
    "titles = {}\n",
    "Path = r\"C:\\Users\\rapha\\Downloads\\SNA_Res_100_pdfs_Files\\SNA_Res_100_pdfs_R_txt\"\n",
    "filelist = os.listdir(Path)\n",
    "titles = filelist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dict to store\n",
    "txt_files = dict(zip(titles,texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_word_list = []\n",
    "for a in word_freq.keys():\n",
    "    top_word_list.append(a)\n",
    "print(len(top_word_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num in top_word_list:\n",
    "    if num.isnumeric() == True:\n",
    "        top_word_list.remove(num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_top_word_list = top_word_list[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_list = []\n",
    "texts = []\n",
    "d = dict()\n",
    "\n",
    "for entry in os.listdir(Path): \n",
    "    with open(entry) as body:\n",
    "        body.read()\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.listdir(Path) \n",
    "dict_list = []\n",
    "d = dict()\n",
    "\n",
    "for text in file_path:\n",
    "   \n",
    "    with open(text) as body:\n",
    "        opened = body.read().split()\n",
    "        \n",
    "        for word in opened:\n",
    "            if word in reduced_top_word_list:\n",
    "                 d[word] = d.get(word, 0) + 1\n",
    "            else:\n",
    "                continue\n",
    "        \n",
    "          \n",
    "        copy = d.copy()\n",
    "        dict_list.append(copy)\n",
    "        d.clear()\n",
    "         \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('precision',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace na with 0\n",
    "df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using total to see which words are found most frequently\n",
    "df.loc['Total']= df.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort the words by high to low\n",
    "\n",
    "df2 = df.iloc[:,np.argsort(-df.loc['Total'])].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can now use drop this row \n",
    "df2.drop('Total', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.style.background_gradient()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
